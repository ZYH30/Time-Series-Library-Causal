# æ–‡ä»¶è·¯å¾„: Time-Series-Library/runLSTMCausalAd.py
import argparse
import os
import torch
import numpy as np
import pandas as pd
from data_provider.data_factory import data_provider
from utils.metrics import metric
from models import LSTMCausalAd
# ä»Žä½ çš„ä»£ç åº“å¯¼å…¥å¯¹æŠ—æŸå¤±
# åœ¨æ–‡ä»¶å¼€å¤´å¯¼å…¥
from utils.tools import EarlyStopping, adjust_learning_rate
# ç¡®ä¿å¯¼å…¥ä½ çš„æŸå¤±å‡½æ•°
from loss import AdversarialLoss 

def prepare_causal_dataset(args):
    """
    [æ ¸å¿ƒåˆ›æ–°ç‚¹] æ‹¦æˆªæ•°æ®ï¼Œè¿›è¡Œä¸­è‹±æ˜ å°„ä¸Žå› æžœç‰¹å¾ç­›é€‰ã€‚
    ä»Žè€Œä¸º TSlib æä¾›ä¸€ä¸ªå¹²å‡€çš„é«˜å› æžœæ€§æ•°æ®é›†ã€‚
    """
    original_path = os.path.join(args.root_path, 'weather.csv')
    df = pd.read_csv(original_path)
    
    # ä¸¥æ ¼ä¸­è‹±æ–‡åˆ—åæ˜ å°„
    english_cols = ['date', 'p_mbar', 'Tdew_degC', 'VPact_mbar', 'H2OC_m', 'sh_g', 
                    'SWDR_W', 'PAR_ol', 'max_PAR', 'rho_g', 'Tlog_degC', 'VPmax_mbar', 
                    'T_degC', 'Tpot_K', 'wd_deg', 'max_wv', 'wv_m', 'VPdef_mbar', 
                    'rh', 'rain_mm', 'raining_s', 'OT']
    
    # å¦‚æžœå½“å‰æ•°æ®åˆ—æ•°å’Œä¸Šè¿°åˆ—è¡¨ä¸€è‡´ï¼Œç›´æŽ¥é‡å‘½å
    if len(df.columns) == len(english_cols):
        df.columns = english_cols
    
    # ç‰¹å¾å­é›†æå–
    if args.past_features:
        selected_cols = ['date'] + args.past_features + [args.target]
        df_causal = df[selected_cols].copy()
    else:
        df_causal = df.copy()
        
    # ä¿å­˜æ²™ç›’æ•°æ®ä¾› TSlib æ¶ˆè´¹
    causal_data_name = 'weather_causal.csv'
    causal_path = os.path.join(args.root_path, causal_data_name)
    df_causal.to_csv(causal_path, index=False)
    
    # åŠ¨æ€ä¿®æ”¹ args è®© TSlib é€‚é…æ–°æ•°æ®
    args.data_path = causal_data_name
    # enc_in = å› æžœç‰¹å¾æ•°é‡ + 1ä¸ªç›®æ ‡å˜é‡
    num_features = len(args.past_features) + 1 if args.past_features else len(df_causal.columns) - 1
    args.enc_in = num_features
    args.dec_in = num_features
    print(f"æ•°æ®æ‹¦æˆªå®Œæˆã€‚ç”Ÿæˆå› æžœæ•°æ®é›†åŒ…å«ç‰¹å¾: {df_causal.columns.tolist()}")

def evaluate_tslib_style(model, dataloader, args):
    """
    ä¸¥æ ¼å¤åˆ» TSlib ä¸­ Exp_Long_Term_Forecast.test() çš„è¯„ä¼°ä¸Žé€†å½’ä¸€åŒ–é€»è¾‘
    ä¿è¯å…¬å¹³æ€§ï¼
    """
    model.eval()
    preds, trues = [], []
    with torch.no_grad():
        for batch_x, batch_y, batch_x_mark, batch_y_mark in dataloader:
            batch_x = batch_x.float().cuda()
            batch_y = batch_y.float().cuda()
            batch_x_mark = batch_x_mark.float().cuda()
            batch_y_mark = batch_y_mark.float().cuda()

            pred_x, outputs = model(batch_x, batch_x_mark, batch_y, batch_y_mark)
            
            # MS ä»»åŠ¡ï¼šåªå–æœ€åŽä¸€ä¸ªç»´åº¦ (OT)
            batch_y = batch_y[:, -args.pred_len:, -1:]
            
            preds.append(outputs.detach().cpu().numpy())
            trues.append(batch_y.detach().cpu().numpy())

    preds = np.concatenate(preds, axis=0)
    trues = np.concatenate(trues, axis=0)
    
    # TSlib æ ‡å¿—æ€§çš„é€†å½’ä¸€åŒ–æœºåˆ¶ (Inverse Transform for MS)
    if dataloader.dataset.scale and args.inverse:
        shape = trues.shape
        scaler = dataloader.dataset.scaler
        # ç”±äºŽæˆ‘ä»¬é¢„æµ‹çš„æ˜¯å•å˜é‡ï¼Œä½† scaler æ˜¯åœ¨å¤šå˜é‡ä¸Š fit çš„ï¼ŒTSlib é€šè¿‡ tile å¤åˆ¶å¯¹é½å½¢çŠ¶
        if preds.shape[-1] != args.enc_in:
            preds_tile = np.tile(preds, [1, 1, int(args.enc_in / preds.shape[-1])])
            trues_tile = np.tile(trues, [1, 1, int(args.enc_in / trues.shape[-1])])
            
            preds = scaler.inverse_transform(preds_tile.reshape(shape[0] * shape[1], -1)).reshape(shape[0], shape[1], args.enc_in)
            trues = scaler.inverse_transform(trues_tile.reshape(shape[0] * shape[1], -1)).reshape(shape[0], shape[1], args.enc_in)
            
            # é€†å½’ä¸€åŒ–åŽæˆªå–çœŸå®žçš„ OT ç»´åº¦
            preds = preds[:, :, -1:]
            trues = trues[:, :, -1:]

    mae, mse, rmse, mape, mspe = metric(preds, trues)
    return mse, mae

def main():
    parser = argparse.ArgumentParser(description='LSTMCausalAd Custom Runner integrated with TSlib')

    # ==========================================================
    # 1. TSlib å®˜æ–¹çŽ¯å¢ƒç»´æŒå‚æ•° (ç»å¯¹å…¨é›†ï¼Œé˜²æ­¢åº•å±‚å„ç§éšè—ä¾èµ–æŠ¥é”™)
    # ==========================================================
    # basic config
    parser.add_argument('--task_name', type=str, default='long_term_forecast')
    parser.add_argument('--is_training', type=int, default=1)
    parser.add_argument('--model_id', type=str, default='weather_causal')
    parser.add_argument('--model', type=str, default='LSTMCausalAd')

    # data loader
    parser.add_argument('--data', type=str, default='custom')
    parser.add_argument('--root_path', type=str, default='./dataset/weather/')
    parser.add_argument('--data_path', type=str, default='weather.csv')
    parser.add_argument('--features', type=str, default='MS')
    parser.add_argument('--target', type=str, default='OT')
    parser.add_argument('--freq', type=str, default='h')
    parser.add_argument('--checkpoints', type=str, default='./checkpoints/')

    # forecasting task
    parser.add_argument('--seq_len', type=int, default=96)
    parser.add_argument('--label_len', type=int, default=48)
    parser.add_argument('--pred_len', type=int, default=96)
    parser.add_argument('--seasonal_patterns', type=str, default='Monthly')
    parser.add_argument('--inverse', action='store_true', default=False)

    # imputation & anomaly detection task
    parser.add_argument('--mask_rate', type=float, default=0.25)
    parser.add_argument('--anomaly_ratio', type=float, default=0.25)

    # model define (TSlib åŽŸç”Ÿç½‘ç»œæ‹“æ‰‘å‚)
    parser.add_argument('--expand', type=int, default=2)
    parser.add_argument('--d_conv', type=int, default=4)
    parser.add_argument('--top_k', type=int, default=5)
    parser.add_argument('--num_kernels', type=int, default=6)
    parser.add_argument('--enc_in', type=int, default=21)
    parser.add_argument('--dec_in', type=int, default=21)
    parser.add_argument('--c_out', type=int, default=21)
    parser.add_argument('--d_model', type=int, default=512)
    parser.add_argument('--n_heads', type=int, default=8)
    parser.add_argument('--e_layers', type=int, default=2)
    parser.add_argument('--d_layers', type=int, default=1)
    parser.add_argument('--d_ff', type=int, default=2048)
    parser.add_argument('--moving_avg', type=int, default=25)
    parser.add_argument('--factor', type=int, default=1)
    parser.add_argument('--distil', action='store_false', default=True)
    parser.add_argument('--dropout', type=float, default=0.1)
    parser.add_argument('--embed', type=str, default='timeF')
    parser.add_argument('--activation', type=str, default='gelu')
    parser.add_argument('--channel_independence', type=int, default=1)
    parser.add_argument('--decomp_method', type=str, default='moving_avg')
    parser.add_argument('--use_norm', type=int, default=1)
    parser.add_argument('--down_sampling_layers', type=int, default=0)
    parser.add_argument('--down_sampling_window', type=int, default=1)
    parser.add_argument('--down_sampling_method', type=str, default=None)
    parser.add_argument('--seg_len', type=int, default=96)

    # optimization
    parser.add_argument('--num_workers', type=int, default=10)
    parser.add_argument('--itr', type=int, default=1)
    parser.add_argument('--train_epochs', type=int, default=10)
    parser.add_argument('--batch_size', type=int, default=32)
    parser.add_argument('--patience', type=int, default=3)
    parser.add_argument('--learning_rate', type=float, default=0.0001)
    parser.add_argument('--des', type=str, default='test')
    parser.add_argument('--loss', type=str, default='MSE')
    parser.add_argument('--lradj', type=str, default='type1')
    parser.add_argument('--use_amp', action='store_true', default=False)

    # GPU
    parser.add_argument('--use_gpu', action='store_true', default=True)
    parser.add_argument('--gpu', type=int, default=0)
    parser.add_argument('--gpu_type', type=str, default='cuda')
    parser.add_argument('--use_multi_gpu', action='store_true', default=False)
    parser.add_argument('--devices', type=str, default='0,1,2,3')

    # de-stationary projector params
    parser.add_argument('--p_hidden_dims', type=int, nargs='+', default=[128, 128])
    parser.add_argument('--p_hidden_layers', type=int, default=2)

    # metrics (dtw)
    parser.add_argument('--use_dtw', action='store_true', default=False)

    # ðŸš¨ å¯¼è‡´æŠ¥é”™çš„ Augmentation å‚æ•°å…¨é›† ðŸš¨
    parser.add_argument('--augmentation_ratio', type=int, default=0)
    parser.add_argument('--seed', type=int, default=2)
    parser.add_argument('--jitter', default=False, action="store_true")
    parser.add_argument('--scaling', default=False, action="store_true")
    parser.add_argument('--permutation', default=False, action="store_true")
    parser.add_argument('--randompermutation', default=False, action="store_true")
    parser.add_argument('--magwarp', default=False, action="store_true")
    parser.add_argument('--timewarp', default=False, action="store_true")
    parser.add_argument('--windowslice', default=False, action="store_true")
    parser.add_argument('--windowwarp', default=False, action="store_true")
    parser.add_argument('--rotation', default=False, action="store_true")
    parser.add_argument('--spawner', default=False, action="store_true")
    parser.add_argument('--dtwwarp', default=False, action="store_true")
    parser.add_argument('--shapedtwwarp', default=False, action="store_true")
    parser.add_argument('--wdba', default=False, action="store_true")
    parser.add_argument('--discdtw', default=False, action="store_true")
    parser.add_argument('--discsdtw', default=False, action="store_true")
    parser.add_argument('--extra_tag', type=str, default="")

    # TimeXer, GCN, TimeFilter ç­‰å‰æ²¿æ‰©å±•ç»„ä»¶å‚æ•°
    parser.add_argument('--patch_len', type=int, default=16)
    parser.add_argument('--node_dim', type=int, default=10)
    parser.add_argument('--gcn_depth', type=int, default=2)
    parser.add_argument('--gcn_dropout', type=float, default=0.3)
    parser.add_argument('--propalpha', type=float, default=0.3)
    parser.add_argument('--conv_channel', type=int, default=32)
    parser.add_argument('--skip_channel', type=int, default=32)
    parser.add_argument('--individual', action='store_true', default=False)
    parser.add_argument('--alpha', type=float, default=0.1)
    parser.add_argument('--top_p', type=float, default=0.5)
    parser.add_argument('--pos', type=int, choices=[0, 1], default=1)

    # ==========================================================
    # 2. è‡ªç ”æ¨¡åž‹ LSTMCausalAd ä¸“å±žå‚æ•°
    # ==========================================================
    parser.add_argument('--past_features', nargs='*', 
                        default=['wd_deg', 'SWDR_W', 'max_wv', 'wv_m', 'rho_g', 'max_PAR', 'VPdef_mbar', 'PAR_ol', 'VPmax_mbar', 'rh', 'Tpot_K'])
    parser.add_argument('--forward_features', nargs='*', default=['month', 'year'])
    parser.add_argument('--hidden_size', type=int, default=128, help='LSTMéšè—å±‚ç»´åº¦')
    parser.add_argument('--num_layers', type=int, default=2, help='LSTMå †å å±‚æ•°')
    parser.add_argument('--embedding_size', type=int, default=128, help='åµŒå…¥å±‚ç»´åº¦')
    parser.add_argument('--hidden_size_target', type=int, default=128)
    parser.add_argument('--attn_head_target', type=int, default=8)
    
    parser.add_argument('--normal_epochs', type=int, default=5)
    parser.add_argument('--adv_epochs', type=int, default=5)
    parser.add_argument('--adv_weight', type=float, default=0.001)
    parser.add_argument('--nor_weight', type=float, default=1.0)
    parser.add_argument('--lr_adv', type=float, default=0.005)
    parser.add_argument('--share_outNet', type=bool, default=True)

    args = parser.parse_args()

    # --- 1. æ•°æ®æ‹¦æˆªæ²™ç›’ ---
    prepare_causal_dataset(args)
    
    # --- 2. è°ƒç”¨ TSlib å®˜æ–¹æ•°æ®æµ ---
    train_data, train_loader = data_provider(args, flag='train')
    vali_data, vali_loader = data_provider(args, flag='val')
    test_data, test_loader = data_provider(args, flag='test')

    # 3. åˆå§‹åŒ–å› æžœæ¨¡åž‹ä¸Žå¯¹æŠ—ä¼˜åŒ–å™¨
    model = LSTMCausalAd.Model(args).cuda()
    
    x_params = list(model.feature_tower.outNet.parameters())
    y_params = [p for n, p in model.feature_tower.named_parameters() if not n.startswith('outNet.')] + list(model.target_tower.parameters())
    
    # ==========================================
    # ä¸¥æ ¼å¯¹é½åŽŸé¡¹ç›®çš„å­—å…¸åž‹ä¼˜åŒ–å™¨æœºåˆ¶
    # ==========================================
    optim_x = torch.optim.Adam(x_params, lr=args.lr_adv, weight_decay=6.25e-05)
    optim_y = torch.optim.Adam(y_params, lr=args.learning_rate, weight_decay=6.25e-05)
    
    # âš ï¸ ã€ä¸€æ¯”ä¸€å¤åˆ»ç‚¹ 1ã€‘: æž„å»ºåŽŸé¡¹ç›® train.py ä¸­çš„ optimizers å­—å…¸
    optimizers = {'x': optim_x, 'y': optim_y}
    
    criterion = AdversarialLoss(args.adv_weight, args.nor_weight, 'MSE')
    early_stopping = EarlyStopping(patience=args.patience, verbose=True)

    # ==========================================
    # å¼€å§‹è®­ç»ƒå¾ªçŽ¯
    # ==========================================
    for epoch in range(args.train_epochs):
        model.train()
        train_loss = []
        
        for i, (batch_x, batch_y, batch_x_mark, batch_y_mark) in enumerate(train_loader):
            batch_x = batch_x.float().cuda()
            batch_y = batch_y.float().cuda()
            batch_x_mark = batch_x_mark.float().cuda()
            batch_y_mark = batch_y_mark.float().cuda()

            # 1. æ¨¡åž‹å‰å‘ä¼ æ’­ (è¿”å›žåŒè½¨é¢„æµ‹å¼ é‡)
            pred_x, pred_y = model(batch_x, batch_x_mark, batch_y, batch_y_mark)
            
            # 2. ðŸŽ¯ å¼ é‡è¯­ä¹‰ä¸¥æ ¼æ˜ å°„è‡³åŽŸé¡¹ç›® API ðŸŽ¯
            # (1) ç›®æ ‡å¡” (Target Tower) å¯¹é½
            outputs = pred_y
            labels = batch_y[:, -args.pred_len:, -1:]  # æœªæ¥çš„çœŸå®žç›®æ ‡ OT
            
            # (2) ç‰¹å¾å¡” (Feature Tower) é‡æž„å¯¹é½
            pred_pre_y = pred_x
            
            # åŠ¨æ€æ‹¼æŽ¥å®Œæ•´çš„çœŸå®žåŽ†å²+æœªæ¥åºåˆ—
            y_past = batch_x[:, :, -1:]
            full_y = torch.cat([y_past, labels], dim=1)
            # æ ¹æ® pred_x çš„é•¿åº¦ï¼Œä»Žå³ä¾§å®‰å…¨æˆªå–çœŸå®žçš„ pre_labels
            pre_labels = full_y[:, -pred_pre_y.size(1):, :]
            
            # (3) å¯¹æŠ—åšå¼ˆçŠ¶æ€åˆ¤å®š
            is_adversarial = (epoch >= args.normal_epochs)

            # 3. âš ï¸ ã€ä¸€æ¯”ä¸€å¤åˆ»ç‚¹ 2ã€‘: åŽŸç‰ˆ compute_losses ç­¾åè°ƒç”¨
            loss_result = criterion.compute_losses(
                outputs=outputs,
                labels=labels,
                pre_labels=pre_labels,
                pred_pre_y=pred_pre_y,
                is_adversarial=is_adversarial
            )
            
            # 4. âš ï¸ ã€ä¸€æ¯”ä¸€å¤åˆ»ç‚¹ 3ã€‘: ä¸¥æ ¼éµç…§ä½ æä¾›çš„åŽŸç‰ˆäº¤æ›¿æ›´æ–°é€»è¾‘ä¸Žæ¢¯åº¦æˆªæ–­
            optim = optimizers['x' if loss_result['update_x'] else 'y']
            optim.zero_grad()
            
            loss_result['total_loss'].backward()
            
            # æ¢å¤æžåº¦é‡è¦çš„æ¢¯åº¦æˆªæ–­ï¼Œè¿™æ˜¯é˜²æ­¢ LSTM æ¢¯åº¦çˆ†ç‚¸çš„æ ¸å¿ƒï¼
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0) 
            
            optim.step()
            
            train_loss.append(loss_result['total_loss'].item())

        # ==========================================
        # TSlib æ ‡å‡†åŒ–éªŒè¯æµä¸Žæ—©åœ
        # ==========================================
        val_mse, val_mae = evaluate_tslib_style(model, vali_loader, args)
        print(f"Epoch: {epoch + 1} | Train Loss: {np.average(train_loss):.4f} | Vali MSE: {val_mse:.4f}")
        
        early_stopping(val_mse, model, path='./checkpoints/')
        if early_stopping.early_stop:
            print("è§¦å‘æ—©åœæœºåˆ¶ (Early Stopping)ï¼Œæ¨¡åž‹å·²ç»“æŸè®­ç»ƒã€‚")
            break
            
    # åŠ è½½æœ€ä½³æƒé‡ä»¥è¿›è¡Œæµ‹è¯•é›†è¯„ä¼°
    model.load_state_dict(torch.load('./checkpoints/checkpoint.pth'))
    test_mse, test_mae = evaluate_tslib_style(model, test_loader, args)
    print(f"æœ€ç»ˆæµ‹è¯•é›†ç»“æžœ -> MSE: {test_mse:.4f} | MAE: {test_mae:.4f}")

if __name__ == '__main__':
    main()